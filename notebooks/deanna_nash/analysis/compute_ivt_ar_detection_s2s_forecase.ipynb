{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe6625a-32a7-4fe1-8506-66088759cd13",
   "metadata": {},
   "source": [
    "## Compute ivtx and ivty netcdf for AR detection algorithm\n",
    "**Author: Deanna Nash**\n",
    "\n",
    "This notebook computes ivtx and ivty using the ECMWF QUV.grb files and writes to a netCDF that is compliant for use with the Guan and Waliser AR detection algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8b02313-ed14-4943-925c-ad450613356c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ncar/usr/jupyterhub/envs/cmip6-201910a/lib/python3.7/site-packages/intake/source/discovery.py:136: FutureWarning: The drivers ['stac-catalog', 'stac-collection', 'stac-item'] do not specify entry_points and were only discovered via a package scan. This may break in a future release of intake. The packages should be updated.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "from netCDF4 import Dataset\n",
    "import netCDF4 as nc\n",
    "import cftime\n",
    "from datetime import datetime, timedelta\n",
    "from netCDF4 import num2date, date2num\n",
    "import time as time2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import eofs\n",
    "from eofs.standard import Eof\n",
    "import glob\n",
    "\n",
    "# you need intake-esm V 2020.11.4 and intake V 0.6.0\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "from shapely.geometry.polygon import LinearRing\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from netCDF4 import Dataset\n",
    "from matplotlib import cm\n",
    "\n",
    "import copy\n",
    "import fsspec\n",
    "import intake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "832537ac-769d-4b69-bccf-a7d8d6ec79fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/glade/scratch/dlnash/data/ECMWF/'\n",
    "aneesh_data = '/glade/scratch/acsubram/S2S_Database/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2c498e-631e-4d03-8581-5c7f4670b7f0",
   "metadata": {},
   "source": [
    "## Compute ivtx and ivty for selected initialization date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b97c5b04-05ee-499f-b1f8-9576d9315df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "# for file in glob.glob(aneesh_data + \"QUV_20170119.grb\"):\n",
    "# Read Control Run\n",
    "ds = aneesh_data + \"QUV_20170119.grb\"\n",
    "dsopen = xr.open_dataset(ds, engine='cfgrib')\n",
    "u = dsopen['u']\n",
    "v = dsopen['v']\n",
    "q = dsopen['q']\n",
    "time_ctl = dsopen['time']\n",
    "lon_ctl = dsopen['longitude']\n",
    "lat_ctl = dsopen['latitude']\n",
    "ens_ctl = dsopen['number']\n",
    "step_ctl = dsopen['step']\n",
    "prs_ctl = dsopen['isobaricInhPa']\n",
    "# calculate the zonal and meridional horizontal vapour transport\n",
    "# Pressure levels: 1000 925 850 700 500 300 200\n",
    "\n",
    "\n",
    "#200 - 300mb\n",
    "qu0 = np.mean(q.sel(isobaricInhPa=[200,300]),axis=2) * np.mean(u.sel(isobaricInhPa=[200,300]),axis=2)*10000/9.8\n",
    "#300 - 500mb\n",
    "qu1 = np.mean(q.sel(isobaricInhPa=[300,500]),axis=2) * np.mean(u.sel(isobaricInhPa=[300,500]),axis=2)*20000/9.8\n",
    "#500 - 700 mb\n",
    "qu2 = np.mean(q.sel(isobaricInhPa=[500,700]),axis=2) * np.mean(u.sel(isobaricInhPa=[500,700]),axis=2)*20000/9.8\n",
    "#700 - 850 mb\n",
    "qu3 = np.mean(q.sel(isobaricInhPa=[700,850]),axis=2) * np.mean(u.sel(isobaricInhPa=[700,850]),axis=2)*15000/9.8\n",
    "#850 - 925 mb\n",
    "qu4 = np.mean(q.sel(isobaricInhPa=[850,925]),axis=2) * np.mean(u.sel(isobaricInhPa=[850,925]),axis=2)*7500/9.8\n",
    "#925 - 1000 mb\n",
    "qu5 = np.mean(q.sel(isobaricInhPa=[925,1000]),axis=2) * np.mean(u.sel(isobaricInhPa=[925,1000]),axis=2)*7500/9.8\n",
    "\n",
    "qu = qu0+qu1+qu2+qu3+qu4+qu5\n",
    "\n",
    "\n",
    "#200 - 300mb\n",
    "qv0 = np.mean(q.sel(isobaricInhPa=[200,300]),axis=2) * np.mean(v.sel(isobaricInhPa=[200,300]),axis=2)*10000/9.8\n",
    "#300 - 500mb\n",
    "qv1 = np.mean(q.sel(isobaricInhPa=[300,500]),axis=2) * np.mean(v.sel(isobaricInhPa=[300,500]),axis=2)*20000/9.8\n",
    "#500 - 700 mb\n",
    "qv2 = np.mean(q.sel(isobaricInhPa=[500,700]),axis=2) * np.mean(v.sel(isobaricInhPa=[500,700]),axis=2)*20000/9.8\n",
    "#700 - 850 mb\n",
    "qv3 = np.mean(q.sel(isobaricInhPa=[700,850]),axis=2) * np.mean(v.sel(isobaricInhPa=[700,850]),axis=2)*15000/9.8\n",
    "#850 - 925 mb\n",
    "qv4 = np.mean(q.sel(isobaricInhPa=[850,925]),axis=2) * np.mean(v.sel(isobaricInhPa=[850,925]),axis=2)*7500/9.8\n",
    "#925 - 1000 mb\n",
    "qv5 = np.mean(q.sel(isobaricInhPa=[925,1000]),axis=2) * np.mean(v.sel(isobaricInhPa=[925,1000]),axis=2)*7500/9.8\n",
    "\n",
    "\n",
    "qv = qv0+qv1+qv2+qv3+qv4+qv5\n",
    "\n",
    "tmp = xr.Dataset({'ivtx': qu,\n",
    "                  'ivty': qv})\n",
    "tmp['ivtx'] = qu\n",
    "tmp['ivty'] = qv\n",
    "\n",
    "\n",
    "#     tmp['lev'] = ('lev', [1])\n",
    "#     tmp = tmp.set_coords('lev')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8a13b05-3051-4c20-832e-e7e93af15ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hack for times so they aren't in a gregorian calendar which the algorithm did not like\n",
    "# initialization date\n",
    "t1 = pd.date_range(start='2017-01-19', end='2017-01-19', freq='1D')\n",
    "# valid times\n",
    "times_lst = pd.date_range(start='2017-01-19', end='2017-03-06', freq='1D')\n",
    "times_lst\n",
    "\n",
    "dates=times_lst.tolist()\n",
    "units=\"days since 1900-01-01 00\"\n",
    "cal = 'standard'\n",
    "timez = nc.date2num(dates, units, calendar=cal)\n",
    "time1 = nc.date2num(t1.tolist(), units, calendar=cal)\n",
    "# cftime.date2index(times_lst, nctime, calendar=None, select='exact', has_year_zero=None)\n",
    "\n",
    "# cftime.date2num(dates, units, calendar=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af5e8423-6a2f-4204-b416-a0307ce0a9b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dns = xr.Dataset(\n",
    "# {\n",
    "#     \"ivtx\": (['ens', 'time', 'lat', 'lon'], tmp.ivtx.values),\n",
    "#     \"ivty\": (['ens', 'time', 'lat', 'lon'], tmp.ivty.values)\n",
    "# },\n",
    "# coords={\n",
    "#     \"ens\":  tmp.number.values, # ensemble number\n",
    "#     \"time\":  timez, # days since initialization date\n",
    "#     \"lat\":tmp.latitude.values,\n",
    "#     \"lon\":tmp.longitude.values,\n",
    "# },)\n",
    "\n",
    "# # dimensions:\n",
    "# #         lon = 240 ;\n",
    "# #         lat = 121 ;\n",
    "# #         lev = 47 ; # change to step\n",
    "# #         time = UNLIMITED ; // (1 currently)\n",
    "# #         ens = 11 ; # number\n",
    "    \n",
    "    \n",
    "# dns = dns.expand_dims(dim={\"lev\":1}) # initialization date\n",
    "# dns['lev'] = ('lev', [1])\n",
    "# dns = dns.set_coords('lev')\n",
    "# dns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3205bb5e-35f3-445d-bf95-54c618f9e8fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (ens: 50, lat: 121, lev: 47, lon: 240, time: 1)\n",
       "Coordinates:\n",
       "  * ens      (ens) int64 1 2 3 4 5 6 7 8 9 10 ... 41 42 43 44 45 46 47 48 49 50\n",
       "  * lev      (lev) int64 0 1 2 3 4 5 6 7 8 9 ... 37 38 39 40 41 42 43 44 45 46\n",
       "  * lat      (lat) float64 90.0 88.5 87.0 85.5 84.0 ... -85.5 -87.0 -88.5 -90.0\n",
       "  * lon      (lon) float64 0.0 1.5 3.0 4.5 6.0 ... 352.5 354.0 355.5 357.0 358.5\n",
       "  * time     (time) float64 4.275e+04\n",
       "Data variables:\n",
       "    ivtx     (time, ens, lev, lat, lon) float32 -26.485043 ... 7.4784155\n",
       "    ivty     (time, ens, lev, lat, lon) float32 -2.9125767 ... 0.4839363"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dns = xr.Dataset(\n",
    "{\n",
    "    \"ivtx\": (['ens', 'lev', 'lat', 'lon'], tmp.ivtx.values),\n",
    "    \"ivty\": (['ens', 'lev', 'lat', 'lon'], tmp.ivty.values)\n",
    "},\n",
    "coords={\n",
    "    \"ens\":  tmp.number.values, # ensemble number\n",
    "    \"lev\":  np.arange(len(tmp.valid_time.values)), # days since initialization date\n",
    "    \"lat\":tmp.latitude.values,\n",
    "    \"lon\":tmp.longitude.values,\n",
    "},)\n",
    "\n",
    "# dimensions:\n",
    "#         lon = 240 ;\n",
    "#         lat = 121 ;\n",
    "#         lev = 47 ; # change to step\n",
    "#         time = UNLIMITED ; // (1 currently)\n",
    "#         ens = 11 ; # number\n",
    "    \n",
    "# add time dimension    \n",
    "dns = dns.expand_dims(dim={\"time\":1}) # initialization date\n",
    "# dns['time'] = ('time', [time1])\n",
    "\n",
    "dns = dns.assign(time=lambda dns: time1)\n",
    "dns = dns.set_coords('time')\n",
    "\n",
    "\n",
    "  # update time attributes\n",
    "dns.time.attrs = dict(\n",
    "        units=\"days since 1900-01-01 00\",\n",
    "        calendar='standard'\n",
    "    )\n",
    "\n",
    "print(dns.time.attrs)\n",
    "\n",
    "# reorder dimensions\n",
    "dns = dns.transpose('ens', 'time', 'lev', 'lat', 'lon')\n",
    "dns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e392d815-2183-4b88-83a2-29178b459d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to ds with time as unlimited dimension\n",
    "dns.to_netcdf(path_to_data+\"IVT_20170119.nc\", unlimited_dims=['time'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMIP6 2019.10a",
   "language": "python",
   "name": "cmip6-201910a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
